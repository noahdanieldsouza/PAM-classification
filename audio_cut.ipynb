{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBo5qv6E+tAqKUsekwwOHE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noahdanieldsouza/PAM-classification/blob/main/audio_cut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEm3AST_sclR"
      },
      "outputs": [],
      "source": [
        "#@title Install Libraries { vertical-output: true }\n",
        "pip install pydub librosa numpy scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports { vertical-output: true }\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "jBVJz1k1srPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configuration { vertical-output: true }\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "WAV_DIR = '' #@param {type:'string'}\n",
        "OUTPUT_DIR = '' #@param {type:'string'}\n",
        "EVENT_THRESHOLD_DB = -30  #@param {type:'int'} # in dB, adjust based on your noise level\n",
        "MIN_SILENCE_DURATION = 0.3 #@param {type:'float'} # seconds\n",
        "CLIP_LENGTH = 5  #@param {type:'int'} second\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "FGTF6BEHtFKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Functions { vertical-output: true }\n",
        "#parse xml timestamps\n",
        "def parse_xml_time(xml_path):\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Look for the right <PROC_EVENT> with <WavFileHandler SamplingStartTimeLocal=... />\n",
        "    for proc_event in root.findall(\".//PROC_EVENT\"):\n",
        "        wav_handler = proc_event.find(\"WavFileHandler\")\n",
        "        if wav_handler is not None:\n",
        "            start_time_str = wav_handler.attrib.get(\"SamplingStartTimeLocal\")\n",
        "            if start_time_str:\n",
        "                return datetime.fromisoformat(start_time_str)\n",
        "\n",
        "    raise ValueError(f\"SamplingStartTimeLocal not found in {xml_path}\")\n",
        "\n",
        "#convert decibels to amplitude\n",
        "def db_to_amplitude_ratio(db):\n",
        "    return 10 ** (db / 20)\n",
        "\n",
        "#detect audio events\n",
        "def detect_events(audio, sr, threshold_db=-30):\n",
        "    # Convert to mono\n",
        "    if audio.ndim > 1:\n",
        "        audio = np.mean(audio, axis=1)\n",
        "\n",
        "    frame_length = int(sr * 0.1)  # 100ms\n",
        "    hop_length = int(sr * 0.05)\n",
        "    rms = librosa.feature.rms(audio, frame_length=frame_length, hop_length=hop_length)[0]\n",
        "    times = librosa.frames_to_time(np.arange(len(rms)), sr=sr, hop_length=hop_length)\n",
        "\n",
        "    threshold = db_to_amplitude_ratio(threshold_db)\n",
        "    is_loud = rms > threshold\n",
        "\n",
        "    events = []\n",
        "    start = None\n",
        "    for i, loud in enumerate(is_loud):\n",
        "        if loud and start is None:\n",
        "            start = times[i]\n",
        "        elif not loud and start is not None:\n",
        "            end = times[i]\n",
        "            if end - start > MIN_SILENCE_DURATION:\n",
        "                events.append((start, end))\n",
        "            start = None\n",
        "    if start is not None:\n",
        "        events.append((start, times[-1]))\n",
        "    return events\n",
        "\n",
        "#create new xml for the five second clip\n",
        "def write_xml_for_clip(base_datetime, clip_start, output_path):\n",
        "    clip_time = base_datetime + timedelta(seconds=clip_start)\n",
        "    clip_time_str = clip_time.isoformat()  # e.g., \"2024-08-31T14:02:15\"\n",
        "\n",
        "    # Root element\n",
        "    root = ET.Element(\"ST\")\n",
        "\n",
        "    # PROC_EVENT structure\n",
        "    proc_event = ET.SubElement(root, \"PROC_EVENT\", attrib={\"ID\": \"4\"})\n",
        "    ET.SubElement(proc_event, \"WavFileHandler\", attrib={\n",
        "        \"SamplingStartTimeLocal\": clip_time_str\n",
        "    })\n",
        "\n",
        "    # Save to file\n",
        "    tree = ET.ElementTree(root)\n",
        "    tree.write(output_path)\n"
      ],
      "metadata": {
        "id": "2YeBFLijtbgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cut audio and save { vertical-output: true }\n",
        "def process_file(wav_path, xml_path):\n",
        "    print(f\"Processing: {os.path.basename(wav_path)}\")\n",
        "\n",
        "    base_time = parse_xml_time(xml_path)\n",
        "    y, sr = librosa.load(wav_path, sr=None)\n",
        "    audio = AudioSegment.from_file(wav_path)\n",
        "\n",
        "    events = detect_events(y, sr, threshold_db=EVENT_THRESHOLD_DB)\n",
        "\n",
        "    base_name = os.path.splitext(os.path.basename(wav_path))[0]\n",
        "    for i, (start, end) in enumerate(events):\n",
        "        duration = end - start\n",
        "        clip_count = int(np.ceil(duration / CLIP_LENGTH))\n",
        "        for j in range(clip_count):\n",
        "            clip_start = start + j * CLIP_LENGTH\n",
        "            actual_start_ms = int(clip_start * 1000)\n",
        "            clip = audio[actual_start_ms:actual_start_ms + CLIP_LENGTH * 1000]\n",
        "\n",
        "            clip_suffix = f\"{base_name}_event{i+1}_{j+1}of{clip_count}\"\n",
        "            wav_out_path = os.path.join(OUTPUT_DIR, f\"{clip_suffix}.wav\")\n",
        "            xml_out_path = os.path.join(OUTPUT_DIR, f\"{clip_suffix}.xml\")\n",
        "\n",
        "            clip.export(wav_out_path, format=\"wav\")\n",
        "            write_xml_for_clip(base_time, clip_start, xml_out_path)\n",
        "\n",
        "for filename in os.listdir(WAV_DIR):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        wav_path = os.path.join(WAV_DIR, filename)\n",
        "        xml_path = os.path.join(WAV_DIR, filename.replace(\".wav\", \".xml\"))\n",
        "        if os.path.exists(xml_path):\n",
        "            process_file(wav_path, xml_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "j8ix-sjCnzkx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}